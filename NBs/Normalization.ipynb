{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, mean as _mean, stddev as _stddev, col , collect_list , monotonically_increasing_id\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy\n",
    "from numpy import allclose\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "import threading\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Program Files\\\\Spark\\\\spark-3.5.1-bin-hadoop3'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"My Spark App\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genre: string (nullable = true)\n",
      " |-- danceability: double (nullable = true)\n",
      " |-- energy: double (nullable = true)\n",
      " |-- key: double (nullable = true)\n",
      " |-- loudness: double (nullable = true)\n",
      " |-- mode: double (nullable = true)\n",
      " |-- speechiness: double (nullable = true)\n",
      " |-- acousticness: double (nullable = true)\n",
      " |-- instrumentalness: double (nullable = true)\n",
      " |-- liveness: double (nullable = true)\n",
      " |-- valence: double (nullable = true)\n",
      " |-- tempo: double (nullable = true)\n",
      " |-- duration_ms: double (nullable = true)\n",
      " |-- lyrics: string (nullable = true)\n",
      "\n",
      "18184\n"
     ]
    }
   ],
   "source": [
    "features_genre_df = spark.read.csv(\"../databases/OLD/cleaned_songs.csv\", header=True, inferSchema=True)\n",
    "features_genre_df = features_genre_df.na.drop()\n",
    "\n",
    "\n",
    "features_genre_df.printSchema()\n",
    "\n",
    "print(features_genre_df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18184\n"
     ]
    }
   ],
   "source": [
    "features = [col_name for col_name in features_genre_df.columns if (col_name != \"genre\" and col_name != \"lyrics\" )]\n",
    "\n",
    "print(features_genre_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_z_map_reduce(one_feature_df):\n",
    "    \n",
    "    count = one_feature_df.count()\n",
    "    # reduce keys\n",
    "    reduce_keys = []\n",
    "    \n",
    "    \n",
    "    # Adding an index to the DataFrame\n",
    "    indexed_df = one_feature_df.withColumn(\"index\", monotonically_increasing_id())\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def z_score_map(start_index , size):\n",
    "        data = indexed_df.filter((col(\"index\") >= start_index) & (col(\"index\") < start_index + size)).toPandas().to_numpy()\n",
    "        for value , _ in data:\n",
    "            reduce_keys.append( ( value , value**2  ,1 ) )\n",
    "        \n",
    "        return\n",
    "    def z_score_reduce():\n",
    "        sum_value = 0\n",
    "        sum_of_squares = 0\n",
    "        count = 0\n",
    "        for key in reduce_keys:\n",
    "            \n",
    "            sum_value += key[0]\n",
    "            sum_of_squares += key[1]\n",
    "            count += key[2]\n",
    "        mean = sum_value / count\n",
    "        variance = (sum_of_squares - (sum_value**2 / count)) / count\n",
    "        stddev = variance ** 0.5\n",
    "        return (mean , stddev)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    count = one_feature_df.count()\n",
    "    \n",
    "    # get number of cores to get best threads size\n",
    "    num_cores = os.cpu_count()\n",
    "    \n",
    "\n",
    "    \n",
    "    chunk_size = indexed_df.count() // num_cores\n",
    "    \n",
    "    threads = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    #apply map function\n",
    "    for i in range(num_cores):\n",
    "        start_index = i * chunk_size\n",
    "        size = chunk_size\n",
    "        if i == num_cores - 1:\n",
    "            size = chunk_size + (count%num_cores)\n",
    "                \n",
    "        # Create a thread object\n",
    "        thread = threading.Thread(target=z_score_map, args=(start_index, size))\n",
    "\n",
    "        # Start the thread\n",
    "        thread.start()\n",
    "\n",
    "        threads.append(thread)\n",
    "    \n",
    "    #collect threads\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    # call reduce function\n",
    "    mean , stddev = z_score_reduce()\n",
    "\n",
    "    return mean , stddev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "def apply_max_map_reduce(one_feature_df):\n",
    "\n",
    "    count = one_feature_df.count()\n",
    "    \n",
    "    # get number of cores to get best threads size\n",
    "    num_cores = os.cpu_count()\n",
    "    \n",
    "    # reduce keys\n",
    "    reduce_keys = []\n",
    "    \n",
    "    # Adding an index to the DataFrame\n",
    "    indexed_df = one_feature_df.withColumn(\"index\", monotonically_increasing_id())\n",
    "    \n",
    "    chunk_size = indexed_df.count() // num_cores\n",
    "    \n",
    "    threads = []\n",
    "\n",
    "\n",
    "    def abs_max_map(start_index , size):\n",
    "        data = indexed_df.filter((col(\"index\") >= start_index) & (col(\"index\") < start_index + size)).toPandas().to_numpy()\n",
    "        for value in data:\n",
    "            reduce_keys.append( abs(value[0]) )\n",
    "    \n",
    "    def abs_max_reduce():\n",
    "        max_value = reduce_keys[0]\n",
    "        for key in reduce_keys:\n",
    "            if key > max_value:\n",
    "                max_value = key\n",
    "        return max_value\n",
    "\n",
    "\n",
    "    #apply map function\n",
    "    for i in range(num_cores):\n",
    "        start_index = i * chunk_size\n",
    "        size = chunk_size\n",
    "        if i == num_cores - 1:\n",
    "            size = chunk_size + (count%num_cores)\n",
    "                \n",
    "        # Create a thread object\n",
    "        thread = threading.Thread(target=abs_max_map, args=(start_index, size))\n",
    "\n",
    "        # Start the thread\n",
    "        thread.start()\n",
    "\n",
    "        threads.append(thread)\n",
    "    \n",
    "    #collect threads\n",
    "    \n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    \n",
    "    # call reduce function\n",
    "    max_value = abs_max_reduce()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    return max_value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.31230487177106014\n",
      "Mean: 7.95929908614499e-12\n",
      "Max Value: 3.2019993615118003\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.001582451594984059\n",
      "Mean: -0.9940974564614363\n",
      "Max Value: 3.729999424483588\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 3.6230354921589285\n",
      "Mean: 5.362145390070922\n",
      "Max Value: 1.556113546811969\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 2.9428110994334817\n",
      "Mean: -6.773701241134752\n",
      "Max Value: 5.5216927658025305\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.4916735321508524\n",
      "Mean: 0.5908687943262412\n",
      "Max Value: 1.2017502584315527\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.10153846090053874\n",
      "Mean: 0.10653262411347508\n",
      "Max Value: 5.775815101836089\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.2172604826459308\n",
      "Mean: 0.1790764221764182\n",
      "Max Value: 3.714083518532104\n",
      "01515 1515\n",
      " 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.15746058861638335\n",
      "Mean: 0.04687236192819142\n",
      "Max Value: 5.818139295184166\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.16168005357348542\n",
      "Mean: 0.19263878546099264\n",
      "Max Value: 4.94409295934386\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 0.23381654179830258\n",
      "Mean: 0.5266170656028369\n",
      "Max Value: 2.127381842949009\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 27.27369113512582\n",
      "Mean: 120.4433648049644\n",
      "Max Value: 3.210003177101379\n",
      "0 1515\n",
      "1515 1515\n",
      "3030 1515\n",
      "4545 1515\n",
      "6060 1515\n",
      "7575 1515\n",
      "9090 1515\n",
      "10605 1515\n",
      "12120 1515\n",
      "13635 1515\n",
      "15150 1515\n",
      "16665 1519\n",
      "Standard Deviation: 56543.472810401545\n",
      "Mean: 229992.9339539007\n",
      "Max Value: 4.9749343657992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index , feature in enumerate(features):\n",
    "    # cast to double\n",
    "    \n",
    "    features_genre_df = features_genre_df.withColumn(feature, col(feature).cast(\"double\"))\n",
    "   \n",
    "   # call map reduce function and get mean and standard deviation\n",
    "   \n",
    "    mean , stddev = apply_z_map_reduce(features_genre_df.select(feature))\n",
    "    \n",
    "    #perform z-score normalization\n",
    "    features_genre_df = features_genre_df.withColumn(feature, (col(feature) - mean) / stddev)\n",
    "    \n",
    "    # make all values lies between -1 and 1\n",
    "    \n",
    "    # get absolute maximum value\n",
    "    \n",
    "    max_value = apply_max_map_reduce(features_genre_df.select(feature))\n",
    "    \n",
    "    # divide by max value\n",
    "    features_genre_df = features_genre_df.withColumn(feature, (col(feature) / max_value))\n",
    "\n",
    "    print(\"Standard Deviation:\", stddev)\n",
    "    print(\"Mean:\", mean)\n",
    "    print (\"Max Value:\", max_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to csv\n",
    "features_genre_df.toPandas().to_csv(\"../databases/OLD/normalized_songs.csv\", index=False , header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_tata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
